{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exact rejection ABC\n",
    "\n",
    "Develop an ABC sampler to estimate the probability $\\pi$ of success in a negative binomial model where exactly $N+n$ trials are needed to obtain $n$ successes and $N$ failures with the last trial being successful.'\n",
    "\n",
    "We assume that $n = 20$ and the data $X$ consists of a single observation $N = 35$.\n",
    "\n",
    "1. Report the mean and standard deviation of the posterior $p(\\pi | X)$ when the prior $p(\\pi) = \\mathrm{Beta}(\\pi; 1.0, 1.0)$.\n",
    "2. Report the mean and standard deviation of the posterior $p(\\pi | X)$ when the prior $p(\\pi) = \\mathrm{Beta}(\\pi; 5.0, 5.0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: Beta(pi,1.0,1.0)\n",
      "mean: 0.3688166074120848 standard deviation: 0.06273258462122211\n",
      "Prior: Beta(pi,5.0,5.0)\n",
      "mean: 0.3839164078088673 standard deviation: 0.06472728605126575\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def abc_negabin(N, n, r, alpha, beta):\n",
    "    samples = np.zeros(N)\n",
    "    nsamples = 0\n",
    "    while nsamples < N:\n",
    "        pr = np.random.beta(alpha, beta, size=1)\n",
    "        if np.random.negative_binomial(n=20,p=pr, size=1) == r:\n",
    "            samples[nsamples] = pr\n",
    "            nsamples += 1\n",
    "    return samples\n",
    "\n",
    "x=abc_negabin(1000,20,35,1.0,1.0)\n",
    "print(\"Prior: Beta(pi,1.0,1.0)\")\n",
    "print(\"mean:\", np.mean(x),\"standard deviation:\",np.std(x))\n",
    "h = plt.hist(x, 30)\n",
    "y=abc_negabin(1000,20,35,5.0,5.0)\n",
    "print(\"Prior: Beta(pi,5.0,5.0)\")\n",
    "print(\"mean:\", np.mean(y),\"standard deviation:\", np.std(y))\n",
    "h = plt.hist(y, 30, color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The effect of $\\epsilon$ in ABC \n",
    "\n",
    "In this exercise we will study the effect of the tolerance parameter $\\epsilon$ in ABC. We will use the data set loaded below as the data set $X = (x_1, \\dots, x_n)$ and $S(X) = \\mathrm{median}(X)$ as the summary statistic.\n",
    "\n",
    "Our model is\n",
    "$$ p(X | \\theta) = \\prod_{i=1}^n \\mathrm{Laplace}(x_i;\\; \\theta, 1) $$\n",
    "with the prior\n",
    "$$ p(\\theta) = \\mathcal{N}(\\theta;\\; 0, 5^2). $$\n",
    "\n",
    "1. Implement an ABC sampler that accepts proposals $\\theta'$ when \n",
    "$$|S(X') - S(X)| < \\epsilon.$$\n",
    "Use your sampler to draw 100 samples with $\\epsilon = 1$, $\\epsilon = 0.1$ and $\\epsilon = 0.01$. Plot a histogram of the samples in each case and compare the results. Report the mean and standard deviation of the samples drawn in each case to Moodle.\n",
    "2. Implement an ABC sampler that accepts proposals $\\theta'$ probabilistically with probability \n",
    "$$ a = \\exp\\left(-\\frac{|S(X') - S(X)|^2}{2\\epsilon^2}\\right).$$\n",
    "Use your sampler to draw 100 samples with $\\epsilon = 1$, $\\epsilon = 0.1$ and $\\epsilon = 0.01$. Plot a histogram of the samples in each case and compare the results. Report the mean and standard deviation of the samples drawn in each case to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon=1:\n",
      "sample mean: 3.7220989454152194 sample standard deviation: 0.5718293277655412\n",
      "Epsilon=0.1:\n",
      "sample mean: 3.8342660580575045 sample standard deviation: 0.07820070000889993\n",
      "Epsilon=0.01:\n",
      "sample mean: 3.8355892930906164 sample standard deviation: 0.04599113372474336\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/toydata.txt', sep='\\t', header=None)\n",
    "data = data.values[:,0]\n",
    "\n",
    "\n",
    "def abc_epsilon(N, epsilon):\n",
    "    samples = np.zeros(N)\n",
    "    nsamples = 0\n",
    "    while nsamples < N:\n",
    "        thetatahti = np.random.normal(0,5, size=1)\n",
    "        if np.abs(np.median(np.random.laplace(loc=thetatahti,scale=1,size=500))- np.median(data))<epsilon:\n",
    "            samples[nsamples] = thetatahti\n",
    "            nsamples += 1\n",
    "    return samples\n",
    "\n",
    "print(\"Epsilon=1:\")\n",
    "print(\"sample mean:\", np.mean(abc_epsilon(100,1)), \"sample standard deviation:\", np.std(abc_epsilon(100,1)))\n",
    "print(\"Epsilon=0.1:\")\n",
    "print(\"sample mean:\", np.mean(abc_epsilon(100,0.1)), \"sample standard deviation:\", np.std(abc_epsilon(100,0.1)))\n",
    "print(\"Epsilon=0.01:\")\n",
    "print(\"sample mean:\", np.mean(abc_epsilon(100,0.01)), \"sample standard deviation:\", np.std(abc_epsilon(100,0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon=1:\n",
      "3.5502094883282154 0.9662659433796258\n",
      "Epsilon=0.1:\n",
      "3.851884815070867 0.11862086874790158\n",
      "Epsilon=0.01:\n",
      "3.8335873870106707 0.04751435826659506\n"
     ]
    }
   ],
   "source": [
    "def abc_epsilon_prob(N, epsilon):\n",
    "    samples = np.zeros(N)\n",
    "    nsamples = 0\n",
    "    while nsamples < N:\n",
    "        thetatahti = np.random.normal(loc=0,scale=5, size=1)\n",
    "        sx=np.median(data)\n",
    "        sxpilkku=np.median(np.random.laplace(loc=thetatahti,scale=1,size=500))\n",
    "        ehto=np.exp(-(np.abs(sxpilkku-sx)**2/(2*epsilon**2)))\n",
    "        if np.random.binomial(n=1,p=ehto)==1:\n",
    "            samples[nsamples] = thetatahti\n",
    "            nsamples += 1\n",
    "    return samples\n",
    "\n",
    "eka=abc_epsilon_prob(100,1)\n",
    "toka=abc_epsilon_prob(100,0.1)\n",
    "kolmas=abc_epsilon_prob(100,0.01)\n",
    "print(\"Epsilon=1:\")\n",
    "print(np.mean(eka), np.std(eka))\n",
    "print(\"Epsilon=0.1:\")\n",
    "print(np.mean(toka), np.std(toka))\n",
    "print(\"Epsilon=0.01:\")\n",
    "print(np.mean(kolmas), np.std(kolmas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that standard deviation decreases with epsilon getting smaller. When epsilon =.01, \n",
    "# the results of both approaches do not differ significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rejection ABC for a dynamical model\n",
    "\n",
    "In this task we will develop an ABC sampler for the autoregressive (AR) model:\n",
    "$$ x_{t+1} = a x_t + \\epsilon_t, \\quad \\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2). $$\n",
    "We assume $x_0 = 1$. The model has two parameters, $a$ and $\\sigma$. We set priors\n",
    "$$ p(a) = \\mathrm{Uniform}(a;\\; 0, 1), \\quad p(\\sigma) = \\mathrm{Gamma}(\\sigma;\\; k_\\sigma, \\theta_\\sigma) $$\n",
    "with $k_\\sigma = 8, \\theta_\\sigma = 1/8$. Note that we use the shape/scale parametrisation also used by NumPy and that the prior is over $\\sigma$, not $\\sigma^2$ (also more consistent with NumPy parametrisation).\n",
    "\n",
    "1. Implement a function to simulate the AR process. Test your function by generating and plotting two independent realisations of length 200 with $a = 0.75$, $\\sigma = 0.2$. Notice how the sequences diverge relatively quickly and are essentially independent toward the end.\n",
    "2. Implement an ABC sampler to infer the posterior over $a$ and $\\sigma$ given the single observed sequence loaded below using the simulator implemented above and the summary statistics\n",
    "$$ S(X) = \\left( \\frac{1}{N} \\sum_{i=1}^N x_i^2, \\frac{1}{N-1} \\sum_{i=1}^{N-1} x_i x_{i+1} \\right). $$\n",
    "Run your sampler to generate samples with acceptance threshold $\\| S(X) - S(X^*)\\|_2 \\le \\epsilon$ with $\\epsilon = 0.2$.\n",
    "3. Report the approximate posterior means and standard deviations of $a$ and $\\sigma$ to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior mean of a: 0.8123661967262644 posterior std of a: 0.06911071183736714\n",
      "Posterior mean of sigma: 0.6803689231830523 posterior std of sigma: 0.11120116170063164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "npr.seed=42\n",
    "\n",
    "dataframe = pd.read_csv('http://www.helsinki.fi/~ahonkela/teaching/compstats1/ar_time_series_data.txt', header=None, sep='\\t')\n",
    "data = dataframe.values[:,0]\n",
    "\n",
    "ksigma=8\n",
    "musigma=1/8\n",
    "\n",
    "ekakompo=(1/len(data))*np.sum(data**2)\n",
    "summa=0\n",
    "for i in range(len(data)-1):\n",
    "    summa=summa+data[i]*data[i+1]\n",
    "tokakompo=(1/((len(data))-1))*summa\n",
    "\n",
    "SX=np.array([ekakompo, tokakompo])\n",
    "\n",
    "\n",
    "def abc_regr(N, epsilon):\n",
    "    samples = np.zeros((N,2))\n",
    "    nsamples = 0\n",
    "    while nsamples < N:\n",
    "        a=np.random.uniform(0,1)\n",
    "        sigma=np.random.gamma(ksigma,musigma)\n",
    "    \n",
    "        x0=1\n",
    "        xs=np.zeros(200)\n",
    "        for i in range(200):\n",
    "            xs[i]=x0\n",
    "            x0=a*x0+np.random.normal(loc=0,scale=sigma)\n",
    "        sa=(1/200)*np.sum(xs**2)\n",
    "    \n",
    "        summa=0\n",
    "        for i in range(len(data)-1):\n",
    "            summa=summa+xs[i]*xs[i+1]\n",
    "        ssigma=(1/((len(data))-1))*summa\n",
    "\n",
    "    \n",
    "        SXTAHTI=np.array([sa,ssigma])\n",
    "        premi=((SXTAHTI[0]-SX[0])**2+(SXTAHTI[1]-SX[1])**2)\n",
    "        ehto=np.sqrt(premi)\n",
    "        if ehto<=epsilon:\n",
    "            samples[nsamples] = np.array([a,sigma])\n",
    "            nsamples += 1\n",
    "    return samples\n",
    "\n",
    "ajo=abc_regr(200,0.2)\n",
    "print(\"Posterior mean of a:\", np.mean(ajo[:,0]),\"posterior std of a:\", np.std(ajo[:,0]))\n",
    "print(\"Posterior mean of sigma:\", np.mean(ajo[:,1]),\"posterior std of sigma:\", np.std(ajo[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
